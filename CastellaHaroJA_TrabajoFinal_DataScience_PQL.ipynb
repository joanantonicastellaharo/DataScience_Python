{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica Final Data Science - Curs 2019/2020. Product Qualified Lead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La situación que se plantea por parte de la empresa 'BetterLife' hace referencia prinicpalmente al cambio de la estratégia comercial. Véase, que en este caso se quiere reemplazar una metodología llamada Marketing Qualified Lead (MQL) por otra que lleva el nombre de Product Qualified Lead (PQL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1. Importaremos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importaremos aquellas librerías que necesitaremos para realizar una lectura del dataset proporcionado por la empresa, \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2. Cargamos DataSet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este caso cargamos las bases de datos dado que se utilizarán a futuro para validar el modelo.\n",
    "df_c = pd.read_excel(\"../Data/data_PQL.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizaremos un primera visualización, \n",
    "df_c.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 3. Comprovamos los datos cargados\n",
    "· describe\n",
    "· shape\n",
    "· nulls\n",
    "· NaN\n",
    "· dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra un resumen de los indicadores estadisticos más usuales, los cuales utilizaremos para \n",
    "# determinar el número inicial de desviaciones estandar para eliminar si existen los outliers.\n",
    "df_c.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra las dimenciones del dataframe\n",
    "df_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de dato para cada columna\n",
    "df_c.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que exiten valores \"null\" en los campos del dataset\n",
    "df_c.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los valores \"NAN\" se distribuyen en los siguientes campos con estas cantidades\n",
    "df_c.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminaremos las filas \"NaN\" en todos sus campos\n",
    "df_c_na = df_c\n",
    "df_c_na.dropna(how='all', inplace=True)\n",
    "\n",
    "# Reemplazamos los registro \"NaN\" de los campos que contengan y los sustituiremos por el valor 0, \n",
    "df_c_na.fillna(0, inplace=True)\n",
    "\n",
    "#De nuevo veremos la forma de nuestro dataframe, \n",
    "df_c_na.shape #COn este resultado podemos observar que ninguno de nuestro registro tiene todos los valores como \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que ya no existen valores \"NaN\"\n",
    "df_c_na.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiaremos aquellas columnas que creemos que no utilizaremos para el train. Solo variables numéricas, \n",
    "\n",
    "df_c_clean = df_c_na.drop([\"country\", \"industry\", \"job_function\",\"job_title\"], axis=1)\n",
    "\n",
    "df_c_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 4. Estudio de las variables de nuestro modelo y su importancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuatro paso queremos eliminar la posibilidad de que exista una situación de sobrentrenamiento de nuestro modelo. De esta forma elinaremos la posibilidad de que nuestro modelo no sirva para futuras predicciones dado que no habrá aprendido nada de forma generalizada. Decidimos realizar este paso dado que el dataset que nos proporciona la empresa tiene más columnas que filas y deberemos determinar a través del Feature Selection qué columnas tendrán una mayor importancia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continaución definiremos aquellas variables independientes para nuestro posterior modelo de entrenamiento y a varibale target, \n",
    "\n",
    "X = df_c_clean.iloc[:,0:302]  \n",
    "df_y = df_c_clean.iloc[:,-2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificaremos la importancia y el peso de cada una de las variables que compenen nuestro DataFrame, \n",
    "#Hemos utilizado el método Tree-based - SelectFromModel\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=302)\n",
    "embeded_rf_selector.fit(X, df_y)\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizaremos una vista de aquellas características que representarán mejor nustro modelo, \n",
    "df_X = embeded_rf_feature\n",
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduciremos nuestro modelo de train para que solo coja aquellas features que hemos definido con mayor improtancia, \n",
    "X_f = df_c_clean[['starts_2day',\n",
    " 'starts_4day',\n",
    " 'starts_6day',\n",
    " 'starts_8day',\n",
    " 'starts_10day',\n",
    " 'starts_12day',\n",
    " 'starts_14day',\n",
    " 'starts_16day',\n",
    " 'starts_18day',\n",
    " 'starts_20day',\n",
    " 'starts_22day',\n",
    " 'starts_24day',\n",
    " 'starts_26day',\n",
    " 'starts_28day',\n",
    " 'starts_30day',\n",
    " 'starts_4day_Delta',\n",
    " 'starts_6day_Delta',\n",
    " 'starts_8day_Delta',\n",
    " 'starts_10day_Delta',\n",
    " 'starts_12day_Delta',\n",
    " 'starts_14day_Delta',\n",
    " 'starts_16day_Delta',\n",
    " 'starts_18day_Delta',\n",
    " 'starts_20day_Delta',\n",
    " 'starts_22day_Delta',\n",
    " 'starts_24day_Delta',\n",
    " 'starts_26day_Delta',\n",
    " 'starts_28day_Delta',\n",
    " 'starts_30day_Delta',\n",
    " 'FormC',\n",
    " 'VisitC',\n",
    " 'WebinarC',\n",
    " 'EventC',\n",
    " 'Form HandlerC',\n",
    " 'Landing PageC',\n",
    " 'Page ViewC',\n",
    " 'Chat TranscriptC',\n",
    " 'Form TrackerC',\n",
    " 'countsum_retrieve',\n",
    " 'countsum_apply_model',\n",
    " 'countsum_filter_examples',\n",
    " 'countsum_join',\n",
    " 'countsum_parallel_decision_tree',\n",
    " 'countsum_performance',\n",
    " 'countsum_read_data_operators',\n",
    " 'countsum_select_attributes',\n",
    " 'countsum_set_role',\n",
    " 'countsum_x_validation',\n",
    " 'countsum_decision_tree',\n",
    " 'countsum_multiply',\n",
    " 'countsum_generate_attributes',\n",
    " 'countsum_sort',\n",
    " 'countsum_store',\n",
    " 'countsum_EXECUTE',\n",
    " 'countsum_FAILURE',\n",
    " 'countsum_USER_ERROR',\n",
    " 'failure_ratio',\n",
    " 'user_error_ratio',\n",
    " 'stopped_ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 5. Entrenamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que ahora ya contamos con un rango de valores para analizar que usuarios comprarán o no nuestra beta, debemos preocuparnos por todo el resto de los campos para que el modelo pueda procesarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importaremos aquellas librerías necesarias para este proceso, \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dentro de nuestra variable a predecir reemplazaremos los valores True y False por los valores binarios 0 y 1. Dado la naturaleza del modelo que utilizaremos durante la predicción, \n",
    "y = df_y.replace(True, 1).replace(False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizaremos el split de nuestro dataset, \n",
    "X_f_train, X_f_test, y_train, y_test = train_test_split(X_f, y, test_size=0.30, random_state=42)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 6. Aplicación del modelo supervisado de clasificación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la naturaleza de la predicción que queremos realizar utilizaremos el modelo de Random Forest Classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 6.1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Aplicamos un bucle para el RFC a cada cluster, en cada iteración asignamos \n",
    "# como valor 1 al label cuando se analiza el clúster especifico y un 0 para el resto de la información\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=0, max_depth = None, \n",
    "                                 min_samples_split = 2, min_samples_leaf = 1, n_jobs=5)\n",
    " # Entrenamiento de lo modelo\n",
    "model_rfc = forest.fit(X_f_train.values,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En este bloque podemos obervar un ranking en las variables utilizadas\n",
    "variablesimportantes = model_rfc.feature_importances_\n",
    "model_rfc_var_import = pd.DataFrame(list(zip(X_f_train.columns,variablesimportantes))).sort_values(1,ascending=False)\n",
    "model_rfc_var_import.columns = [\"Variable\", \"Ranking_RFC\"]\n",
    "model_rfc_var_import.reset_index(drop=True, inplace=True)\n",
    "#model_rfc_var_import.Variable.values.tolist()\n",
    "model_rfc_var_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A continuación realizaremos la aplicación del modelo de RFC, \n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "\n",
    "y_train_pred = model_rfc.predict(X_f_train)\n",
    "y_test_pred = model_rfc.predict(X_f_test)\n",
    "\n",
    "print(\"Accurancy de train es: \",accuracy_score(y_train, y_train_pred))\n",
    "print(\"Accurancy de test es: \",accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar con las transformaciones realizadas y la posterior aplicación del modelo Random Forest Classifier, obtenemos un accuracy del train 98,9% y un accuracy del test del 62,3%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 6.1.1 - Aplicación de Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la situación de la predicción que queremos realizar también utilizaremos el modelo de Logistic Regression para poder realizar una comparación entre ambos modelos y así escojer aquél que no proporciones mejores predicciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Aplicación del Modelo logistico para el dataset, \n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(X_f_train,y_train)\n",
    "# Predicciones y Accurancy del Modelo Logistico\n",
    "y_train_pred_log = model_log.predict(X_f_train)\n",
    "y_test_pred_log = model_log.predict(X_f_test)\n",
    "\n",
    "print(\"Accurancy de train es: \",accuracy_score(y_train, y_train_pred_log))\n",
    "print(\"Accurancy de test es: \",accuracy_score(y_test, y_test_pred_log))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar con las transformaciones realizadas y la posterior aplicación del modelo Logistic Regression, obtenemos un accuracy del train 75,1% y un accuracy del test del 67,1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 7. Cargaremos y realizaremos las transformaciones correspondientes al fichero de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Véase a continuación que haremos una lectura del fichero de predict que nos proporciona la companyía, \n",
    "df_c_pred = pd.read_excel(\"../Data/data_PQLpredict.xlsx\")\n",
    "df_c_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 7.1. Transformación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación realizaremos el mismo proceso de transformación de los datos que hemos llevado a cabo con el data set que nos ha servido para realizar nuestro entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra un resumen de los indicadores estadisticos más usuales, los cuales utilizaremos para \n",
    "# determinar el número inicial de desviaciones estandar para eliminar si existen los outliers.\n",
    "df_c_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra las dimenciones del dataframe\n",
    "df_c_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que exiten valores \"null\" en los campos del dataset\n",
    "df_c_pred.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los valores \"NAN\" se distribuyen en los siguientes campos con estas cantidades\n",
    "df_c_pred.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminaremos las filas \"NaN\" en todos sus campos\n",
    "df_c_na_pred = df_c_pred\n",
    "df_c_na_pred.dropna(how='all', inplace=True)\n",
    "\n",
    "# Reemplazamos los registro \"NaN\" de los campos que contengan y los sustituiremos por el valor 0, \n",
    "df_c_na_pred.fillna(0, inplace=True)\n",
    "\n",
    "#De nuevo veremos la forma de nuestro dataframe, \n",
    "df_c_na_pred.shape #COn este resultado podemos observar que ninguno de nuestro registro tiene todos los valores como \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que ya no existen valores \"NaN\"\n",
    "df_c_na_pred.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiaremos aquellas columnas que creemos que no utilizaremos para el train. Solo variables numéricas, \n",
    "df_c_clean_pred = df_c_na_pred.drop([\"country\", \"industry\", \"job_function\",\"job_title\"], axis=1)\n",
    "df_c_clean_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiremos de nuevo para nuestro DataSet de predicción aquellas características que definirán la predicción,\n",
    "X_f_pred = df_c_clean_pred[['starts_2day',\n",
    " 'starts_4day',\n",
    " 'starts_6day',\n",
    " 'starts_8day',\n",
    " 'starts_10day',\n",
    " 'starts_12day',\n",
    " 'starts_14day',\n",
    " 'starts_16day',\n",
    " 'starts_18day',\n",
    " 'starts_20day',\n",
    " 'starts_22day',\n",
    " 'starts_24day',\n",
    " 'starts_26day',\n",
    " 'starts_28day',\n",
    " 'starts_30day',\n",
    " 'starts_4day_Delta',\n",
    " 'starts_6day_Delta',\n",
    " 'starts_8day_Delta',\n",
    " 'starts_10day_Delta',\n",
    " 'starts_12day_Delta',\n",
    " 'starts_14day_Delta',\n",
    " 'starts_16day_Delta',\n",
    " 'starts_18day_Delta',\n",
    " 'starts_20day_Delta',\n",
    " 'starts_22day_Delta',\n",
    " 'starts_24day_Delta',\n",
    " 'starts_26day_Delta',\n",
    " 'starts_28day_Delta',\n",
    " 'starts_30day_Delta',\n",
    " 'FormC',\n",
    " 'VisitC',\n",
    " 'WebinarC',\n",
    " 'EventC',\n",
    " 'Form HandlerC',\n",
    " 'Landing PageC',\n",
    " 'Page ViewC',\n",
    " 'Chat TranscriptC',\n",
    " 'Form TrackerC',\n",
    " 'countsum_retrieve',\n",
    " 'countsum_apply_model',\n",
    " 'countsum_filter_examples',\n",
    " 'countsum_join',\n",
    " 'countsum_parallel_decision_tree',\n",
    " 'countsum_performance',\n",
    " 'countsum_read_data_operators',\n",
    " 'countsum_select_attributes',\n",
    " 'countsum_set_role',\n",
    " 'countsum_x_validation',\n",
    " 'countsum_decision_tree',\n",
    " 'countsum_multiply',\n",
    " 'countsum_generate_attributes',\n",
    " 'countsum_sort',\n",
    " 'countsum_store',\n",
    " 'countsum_EXECUTE',\n",
    " 'countsum_FAILURE',\n",
    " 'countsum_USER_ERROR',\n",
    " 'failure_ratio',\n",
    " 'user_error_ratio',\n",
    " 'stopped_ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 8. Valoración del campo objetivo mediante el modelo Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizadas todas las transformaciones adecuadas para el tratamiento del nuevo dataset, aplicaremos el modelo que hemos entrenado anteriormente para poder predecir el comportamiento de los usuarios que aparecen en el fichero data_PQLpredict, proporcionado por la empresa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir de los datos que obtenemos de la empresa parar realizar la predicción y utilizando el modelo de entreno,\n",
    "#aplicaremos este mismo modelo entrenado sobre los datos de predicción. Obtendremos el siguiente output, \n",
    "\n",
    "df_predict = pd.DataFrame(model_log.predict(X_f_pred))\n",
    "df_predict\n",
    "\n",
    "#Transformaremos el df_final. Reemplazaremos los valor 1 y 0 por True y False, así obtendremos un un mejor visión de la predicción, \n",
    "df_predict_etl = df_predict.replace(1.0, True).replace(0.0, False)\n",
    "df_predict_etl\n",
    "\n",
    "#Renombraremos la columna output de la predicción, \n",
    "df_predict_etl.rename(columns={0: 'Test_Prediction_PQL'}, inplace=True)\n",
    "df_predict_etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizaremos un concat del dataframe que continene los datos de la predicción con el dataset que obtenemos para predecir, \n",
    "df_final = pd.concat([df_c_pred, df_predict_etl], axis=1)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para poder obtener un output que tenga una mejor estructura solo cojeremos aquellos valores que corresponde a variables \n",
    "#descriptiva y al outout obtenido de la predicción: \n",
    "\n",
    "df_final_sel = df_final[[\"country\", \"industry\", \"job_function\",\"job_title\",\"Test_Prediction_PQL\"]]\n",
    "df_final_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear fichero excel que queremos visualizar en excel y que posteriormente utilizaremos para nuestro análisis,  \n",
    "df_final_sel.to_excel('../Data/Test_Prediction_PQL.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
